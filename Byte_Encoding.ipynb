{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\abbas\\miniconda3\\envs\\bm_1424\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\abbas\\miniconda3\\envs\\bm_1424\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\abbas\\miniconda3\\envs\\bm_1424\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: click in c:\\users\\abbas\\miniconda3\\envs\\bm_1424\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\abbas\\miniconda3\\envs\\bm_1424\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: colorama in c:\\users\\abbas\\miniconda3\\envs\\bm_1424\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Collecting contractions\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting textsearch>=0.0.21\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting anyascii\n",
      "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
      "Collecting pyahocorasick\n",
      "  Downloading pyahocorasick-2.1.0-cp39-cp39-win_amd64.whl (39 kB)\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n",
      "Requirement already satisfied: pandas in c:\\users\\abbas\\miniconda3\\envs\\bm_1424\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abbas\\miniconda3\\envs\\bm_1424\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abbas\\miniconda3\\envs\\bm_1424\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abbas\\miniconda3\\envs\\bm_1424\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\abbas\\miniconda3\\envs\\bm_1424\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abbas\\miniconda3\\envs\\bm_1424\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install contractions\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am Adam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation_special_chars(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "text=remove_punctuation_special_chars(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Abbas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'Adam']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "words=[]\n",
    "def word_Tokenizer(text):\n",
    "    return nltk.tokenize.word_tokenize(text)\n",
    "words=word_Tokenizer(text)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': 1, 'a': 2, 'm': 2, 'A': 1, 'd': 1, '>': 3}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_dict_freq={}\n",
    "for word in words:\n",
    "    for element in word:\n",
    "        # print(element)\n",
    "        if element not in words_dict_freq.keys():\n",
    "            ch=\"\"+element\n",
    "            # print(ch)\n",
    "            words_dict_freq[ch]=1\n",
    "        else:\n",
    "            ch=\"\"+element\n",
    "            words_dict_freq[ch]+=1\n",
    "words_dict_freq[\">\"]=len(words)\n",
    "words_dict_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I>', 'am>', 'Adam>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(words)):\n",
    "    words[i]=words[i]+\">\"\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I>': ['I', '>'], 'am>': ['a', 'm', '>'], 'Adam>': ['A', 'd', 'a', 'm', '>']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_substr={}\n",
    "for word in (words):\n",
    "    if word not in words_substr.keys():\n",
    "        temp=[]\n",
    "        for ele in word:\n",
    "            ch=\"\"+ele\n",
    "            temp.append(ch)\n",
    "        words_substr[word]=temp\n",
    "words_substr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_count(temp):\n",
    "    ans=0\n",
    "    for word in words:\n",
    "        ans+=word.count(temp)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check():\n",
    "    maxi=0\n",
    "    ans=\"\"\n",
    "    for x,y in words_substr.items():\n",
    "        for i in range(len(y)-1):\n",
    "            temp=\"\"\n",
    "            temp+=y[i]\n",
    "            temp+=y[i+1]\n",
    "            ct= check_count(temp)\n",
    "            if(ct>maxi):\n",
    "                maxi=ct\n",
    "                ans=temp\n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_word_substr(ans):\n",
    "    for x,y in words_substr.items():\n",
    "        idx=[]\n",
    "        for i in range(len(y)-1):\n",
    "            temp=\"\"\n",
    "            temp+=y[i]\n",
    "            temp+=y[i+1]\n",
    "            if(temp==ans):\n",
    "                y[i]=ans\n",
    "                idx.append(i+1)\n",
    "        for i in idx:\n",
    "            y.pop(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am\n",
      "am>\n",
      "I>\n",
      "Ad\n",
      "Adam>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['am', 'am>', 'I>', 'Ad', 'Adam>']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=5\n",
    "\n",
    "for i in range(x):\n",
    "    ans=check()\n",
    "    print(ans)\n",
    "    rules.append(ans)\n",
    "    update_word_substr(ans)    \n",
    "\n",
    "rules\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text=\"Adam Madam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am\n",
      "{'Adam>': ['A', 'd', 'am', '>'], 'Madam>': ['M', 'a', 'd', 'am', '>']}\n",
      "am>\n",
      "{'Adam>': ['A', 'd', 'am>'], 'Madam>': ['M', 'a', 'd', 'am>']}\n",
      "I>\n",
      "{'Adam>': ['A', 'd', 'am>'], 'Madam>': ['M', 'a', 'd', 'am>']}\n",
      "Ad\n",
      "{'Adam>': ['Ad', 'am>'], 'Madam>': ['M', 'a', 'd', 'am>']}\n",
      "Adam>\n",
      "{'Adam>': ['Adam>'], 'Madam>': ['M', 'a', 'd', 'am>']}\n"
     ]
    }
   ],
   "source": [
    "test_text=\"Adam Madam\"\n",
    "test_words=word_Tokenizer(test_text)\n",
    "test_words\n",
    "for i in range(len(test_words)):\n",
    "    test_words[i]=test_words[i]+\">\"\n",
    "test_words\n",
    "test_words_substr={}\n",
    "for word in (test_words):\n",
    "    if word not in test_words_substr.keys():\n",
    "        temp=[]\n",
    "        for ele in word:\n",
    "            ch=\"\"+ele\n",
    "            temp.append(ch)\n",
    "        test_words_substr[word]=temp\n",
    "test_words_substr\n",
    "def update_test_words_substr(ans):\n",
    "    for x,y in test_words_substr.items():\n",
    "        idx=[]\n",
    "        for i in range(len(y)-1):\n",
    "            temp=\"\"\n",
    "            temp+=y[i]\n",
    "            temp+=y[i+1]\n",
    "            if(temp==ans):\n",
    "                y[i]=ans\n",
    "                idx.append(i+1)\n",
    "        for i in idx:\n",
    "            y.pop(i)\n",
    "for rule in rules:\n",
    "    print(rule)\n",
    "    for word in test_words:\n",
    "        if(word.count(rule)>0):\n",
    "            update_test_words_substr(rule)  \n",
    "    print(test_words_substr)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adam>>', 'Madam>>']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(test_words)):\n",
    "    test_words[i]=test_words[i]+\">\"\n",
    "test_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adam>>': ['A', 'd', 'a', 'm', '>', '>'],\n",
       " 'Madam>>': ['M', 'a', 'd', 'a', 'm', '>', '>']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_words_substr={}\n",
    "for word in (test_words):\n",
    "    if word not in test_words_substr.keys():\n",
    "        temp=[]\n",
    "        for ele in word:\n",
    "            ch=\"\"+ele\n",
    "            temp.append(ch)\n",
    "        test_words_substr[word]=temp\n",
    "test_words_substr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_test_words_substr(ans):\n",
    "    for x,y in test_words_substr.items():\n",
    "        idx=[]\n",
    "        for i in range(len(y)-1):\n",
    "            temp=\"\"\n",
    "            temp+=y[i]\n",
    "            temp+=y[i+1]\n",
    "            if(temp==ans):\n",
    "                y[i]=ans\n",
    "                idx.append(i+1)\n",
    "        for i in idx:\n",
    "            y.pop(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am\n",
      "{'Adam>>': ['A', 'd', 'am', '>', '>'], 'Madam>>': ['M', 'a', 'd', 'am', '>', '>']}\n",
      "am>\n",
      "{'Adam>>': ['A', 'd', 'am>', '>'], 'Madam>>': ['M', 'a', 'd', 'am>', '>']}\n",
      "I>\n",
      "{'Adam>>': ['A', 'd', 'am>', '>'], 'Madam>>': ['M', 'a', 'd', 'am>', '>']}\n",
      "Ad\n",
      "{'Adam>>': ['Ad', 'am>', '>'], 'Madam>>': ['M', 'a', 'd', 'am>', '>']}\n",
      "Adam>\n",
      "{'Adam>>': ['Adam>', '>'], 'Madam>>': ['M', 'a', 'd', 'am>', '>']}\n"
     ]
    }
   ],
   "source": [
    "for rule in rules:\n",
    "    print(rule)\n",
    "    for word in test_words:\n",
    "        if(word.count(rule)>0):\n",
    "            update_test_words_substr(rule)  \n",
    "    print(test_words_substr)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BM_1424",
   "language": "python",
   "name": "bm_1424"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af14fac318ff6c88ab3002a087017a83add245d2dae3a39dd6aaf919526e258c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
